{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "sdXITx8AAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Tao Ruijie", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=sdXITx8AAAAJ&citpid=5", "affiliation": "Zoom, NUS", "organization": 83442941566286721, "interests": ["Speaker recognition", "speech enhancement", "multi-modal", "self-supervised learning"], "email_domain": "@u.nus.edu", "homepage": "https://taoruijie.github.io/", "citedby": 2312, "publications": {"sdXITx8AAAAJ:r0BpntZqJG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ego4d: Around the world in 3,000 hours of egocentric video", "pub_year": "2022"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:r0BpntZqJG4C", "num_citations": 1508, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17780356579077510129", "cites_id": ["17780356579077510129"]}, "sdXITx8AAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Is someone speaking? exploring long-term temporal features for audio-visual active speaker detection", "pub_year": "2021"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:9ZlFYXVOiuMC", "num_citations": 243, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17419134043437188048,15658058909964517624", "cites_id": ["17419134043437188048", "15658058909964517624"]}, "sdXITx8AAAAJ:QIV2ME_5wuYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-supervised Speaker Recognition with Loss-gated Learning", "pub_year": "2022"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:QIV2ME_5wuYC", "num_citations": 82, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8936700537869538822", "cites_id": ["8936700537869538822"]}, "sdXITx8AAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Muse: Multi-modal target speaker extraction with visual cues", "pub_year": "2021"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:kNdYIx-mwKoC", "num_citations": 76, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4449433196048776546", "cites_id": ["4449433196048776546"]}, "sdXITx8AAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Selective listening by synchronizing speech with lips", "pub_year": "2022"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:e5wmG9Sq2KIC", "num_citations": 60, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15782090029188644569,1722634107055520986", "cites_id": ["15782090029188644569", "1722634107055520986"]}, "sdXITx8AAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-visual speaker recognition with a cross-modal discriminative network", "pub_year": "2020"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:Zph67rFs4hoC", "num_citations": 57, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7974045268553697289", "cites_id": ["7974045268553697289"]}, "sdXITx8AAAAJ:P5F9QuxV20EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Temporal-channel modeling in multi-head self-attention for synthetic speech detection", "pub_year": "2024"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:P5F9QuxV20EC", "num_citations": 36, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2659920044701804125", "cites_id": ["2659920044701804125"]}, "sdXITx8AAAAJ:bEWYMUwI8FkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Speaker recognition with two-step multi-modal deep cleansing", "pub_year": "2023"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:bEWYMUwI8FkC", "num_citations": 31, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5131257423413392088", "cites_id": ["5131257423413392088"]}, "sdXITx8AAAAJ:maZDTaKrznsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Target Active Speaker Detection with Audio-visual Cues", "pub_year": "2023"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:maZDTaKrznsC", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12222525359263617671", "cites_id": ["12222525359263617671"]}, "sdXITx8AAAAJ:_xSYboBqXhAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?", "pub_year": "2024"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:_xSYboBqXhAC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12260025706214562857", "cites_id": ["12260025706214562857"]}, "sdXITx8AAAAJ:Wp0gIr-vW9MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HLT-NUS submission for 2020 NIST conversational telephone speech SRE", "pub_year": "2021"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:Wp0gIr-vW9MC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15669185197955083202", "cites_id": ["15669185197955083202"]}, "sdXITx8AAAAJ:JV2RwH3_ST0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "HLT-NUS submission for 2019 NIST multimedia speaker recognition evaluation", "pub_year": "2020"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:JV2RwH3_ST0C", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18220645307036929507,9898841704427645997", "cites_id": ["18220645307036929507", "9898841704427645997"]}, "sdXITx8AAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Self-Supervised Training of Speaker Encoder with Multi-Modal Diverse Positive Pairs", "pub_year": "2023"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:iH-uZ7U-co4C", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17925756584042613393", "cites_id": ["17925756584042613393"]}, "sdXITx8AAAAJ:SeFeTyx0c_EC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prompt-driven Target Speech Diarization", "pub_year": "2024"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:SeFeTyx0c_EC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8100250711282645565", "cites_id": ["8100250711282645565"]}, "sdXITx8AAAAJ:YFjsv_pBGBYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Emphasized Non-Target Speaker Knowledge in Knowledge Distillation for Automatic Speaker Verification", "pub_year": "2024"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:YFjsv_pBGBYC", "num_citations": 15, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16562973019147452193", "cites_id": ["16562973019147452193"]}, "sdXITx8AAAAJ:CHSYGLWDkRkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Unified audio event detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:CHSYGLWDkRkC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1481255139165454820", "cites_id": ["1481255139165454820"]}, "sdXITx8AAAAJ:NhqRSupF_l8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A benchmark for multi-speaker anonymization", "pub_year": "2025"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:NhqRSupF_l8C", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1293928868194651848", "cites_id": ["1293928868194651848"]}, "sdXITx8AAAAJ:bFI3QPDXJZMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Used: Universal speaker extraction and diarization", "pub_year": "2024"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:bFI3QPDXJZMC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4876723401393226948", "cites_id": ["4876723401393226948"]}, "sdXITx8AAAAJ:EUQCXRtRnyEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Target Speech Diarization with Multimodal Prompts", "pub_year": "2025"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:EUQCXRtRnyEC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13149724579744533676,5383489644364924882", "cites_id": ["13149724579744533676", "5383489644364924882"]}, "sdXITx8AAAAJ:dshw04ExmUIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-Visual Target Speaker Extraction with Selective Auditory Attention", "pub_year": "2025"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:dshw04ExmUIC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9227593720606280442,12075001526302083776", "cites_id": ["9227593720606280442", "12075001526302083776"]}, "sdXITx8AAAAJ:blknAaTinKkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-Visual Active Speaker Extraction for Sparsely Overlapped Multi-talker Speech", "pub_year": "2024"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:blknAaTinKkC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11422752646877001455", "cites_id": ["11422752646877001455"]}, "sdXITx8AAAAJ:pqnbT2bcN3wC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deep Cross-Modal Retrieval Between Spatial Image and Acoustic Speech", "pub_year": "2023"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:pqnbT2bcN3wC", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2043989485199780473", "cites_id": ["2043989485199780473"]}, "sdXITx8AAAAJ:u9iWguZQMMsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "pub_year": "2022"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:u9iWguZQMMsC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3869777117520866210", "cites_id": ["3869777117520866210"]}, "sdXITx8AAAAJ:yD5IFk8b50cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Voice Conversion Augmentation for Speaker Recognition on Defective Datasets", "pub_year": "2025"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:yD5IFk8b50cC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17487774850313788223", "cites_id": ["17487774850313788223"]}, "sdXITx8AAAAJ:cFHS6HbyZ2cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Real-World Active Speaker Detection with Multi-Modal Extraction Pre-Training", "pub_year": "2024"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:cFHS6HbyZ2cC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5886591667422089700", "cites_id": ["5886591667422089700"]}, "sdXITx8AAAAJ:xtRiw3GOFMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Stage Face-Voice Association Learning with Keynote Speaker Diarization", "pub_year": "2024"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:xtRiw3GOFMkC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4068791884206564780", "cites_id": ["4068791884206564780"]}, "sdXITx8AAAAJ:k_IJM867U9cC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "I4U System Description for NIST SRE'20 CTS Challenge", "pub_year": "2022"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:k_IJM867U9cC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9648983353028615519,6818302700330083358", "cites_id": ["9648983353028615519", "6818302700330083358"]}, "sdXITx8AAAAJ:p2g8aNsByqUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "QAMO: Quality-aware Multi-centroid One-class Learning For Speech Deepfake Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:p2g8aNsByqUC", "num_citations": 0}, "sdXITx8AAAAJ:OU6Ihb5iCvQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Addressing Gradient Misalignment in Data-Augmented Training for Robust Speech Deepfake Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:OU6Ihb5iCvQC", "num_citations": 0}, "sdXITx8AAAAJ:uWQEDVKXjbEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Interpolating Speaker Identities in Embedding Space for Data Expansion", "pub_year": "2025"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:uWQEDVKXjbEC", "num_citations": 0}, "sdXITx8AAAAJ:ZHo1McVdvXMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AUDIO-VISUAL ACTIVE SPEAKER DETECTION AND RECOGNITION", "pub_year": "2023"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:ZHo1McVdvXMC", "num_citations": 0}, "sdXITx8AAAAJ:GnPB-g6toBAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Bi-directional Image-Speech Retrieval Through Geometric Consistency", "pub_year": "2023"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:GnPB-g6toBAC", "num_citations": 0}, "sdXITx8AAAAJ:qxL8FJ1GzNcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "NUS-HLT Report for ActivityNet Challenge 2021 AVA (Speaker)", "pub_year": "2021"}, "filled": false, "author_pub_id": "sdXITx8AAAAJ:qxL8FJ1GzNcC", "num_citations": 0}}, "citedby5y": 2310, "hindex": 15, "hindex5y": 15, "i10index": 18, "i10index5y": 18, "cites_per_year": {"2021": 17, "2022": 190, "2023": 461, "2024": 759, "2025": 875}, "updated": "2025-11-01 08:04:36.878161"}